import { IConnection, HttpError } from "@nestia/fetcher";
import { PlainFetcher } from "@nestia/fetcher/lib/PlainFetcher";
import typia from "typia";
import { NestiaSimulator } from "@nestia/fetcher/lib/NestiaSimulator";

import { IDiscussionBoardModerationAuditLog } from "../../../../../structures/IDiscussionBoardModerationAuditLog";
import { IPageIDiscussionBoardModerationAuditLog } from "../../../../../structures/IPageIDiscussionBoardModerationAuditLog";

/**
 * Search and retrieve filtered moderation audit logs for accountability and
 * appeal investigation.
 *
 * Retrieve a comprehensive filtered and paginated list of moderation audit log
 * entries from the discussion_board_moderation_audit_logs table. This operation
 * provides administrators with powerful tools for reviewing moderation
 * decisions, investigating user appeals, monitoring moderator performance, and
 * ensuring consistent application of community guidelines across the platform.
 *
 * Moderation audit logs capture all moderation actions taken by moderators and
 * administrators including content hiding and removal, user warnings, temporary
 * suspensions, permanent bans, appeal approvals and denials, and automated
 * moderation actions. Each log entry records the moderator or administrator
 * identity who performed the action, the target user or content affected,
 * comprehensive reasoning for the decision, preserved content snapshots for
 * appeals investigation, and detailed metadata providing full context for the
 * moderation event.
 *
 * The operation supports extensive filtering capabilities including action type
 * filtering (content_hidden, content_removed, warning_issued, user_suspended,
 * user_banned, appeal_approved, appeal_denied), moderator identity filtering to
 * review specific moderator's decisions, target user filtering for
 * investigating moderation history of particular members, date range queries
 * for temporal pattern analysis, content type filtering to focus on topic or
 * reply moderation, and combined filters for complex audit queries.
 *
 * Administrators rely on this endpoint for multiple critical moderation
 * oversight functions: reviewing moderator decisions for quality assurance and
 * consistency, investigating user appeals by examining original moderation
 * context and reasoning, monitoring moderator performance through decision
 * pattern analysis, identifying potential moderator bias or inconsistent
 * application of guidelines, generating transparency reports showing moderation
 * activity statistics, training new moderators by providing examples of past
 * decisions, and resolving disputes about content removal or user sanctions.
 *
 * Accountability and transparency are paramount for this endpoint. The
 * moderation audit trail serves as the authoritative record for all content
 * governance activities, supporting the platform's commitment to fair and
 * consistent moderation. All moderation actions are permanently logged with
 * immutable records, moderator identities are tracked to enable performance
 * review, comprehensive reasoning is required for all moderation decisions,
 * content snapshots preserve the exact state at time of action, and metadata
 * provides full context for understanding each moderation event.
 *
 * The response includes paginated moderation audit entries with complete action
 * details, filtering metadata showing applied search criteria, aggregated
 * statistics for moderation patterns and trends, and sorting options by
 * timestamp, action type, or moderator identity to support different audit and
 * review workflows.
 *
 * Integration with the appeals system is critical as this endpoint provides the
 * foundational data for appeal investigations, allowing administrators to
 * review original moderation decisions with full context, examine moderator
 * reasoning, access preserved content snapshots, and make informed decisions on
 * whether to uphold, reverse, or modify contested moderation actions.
 *
 * @param props.connection
 * @param props.body Search criteria and filtering parameters for moderation
 *   audit log retrieval including action types, moderator identifiers, target
 *   users, date ranges, and content references
 * @path /discussionBoard/administrator/audit/moderation
 * @accessor api.functional.discussionBoard.administrator.audit.moderation.index
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function index(
  connection: IConnection,
  props: index.Props,
): Promise<index.Response> {
  return true === connection.simulate
    ? index.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...index.METADATA,
          path: index.path(),
          status: null,
        },
        props.body,
      );
}
export namespace index {
  export type Props = {
    /**
     * Search criteria and filtering parameters for moderation audit log
     * retrieval including action types, moderator identifiers, target
     * users, date ranges, and content references
     */
    body: IDiscussionBoardModerationAuditLog.IRequest;
  };
  export type Body = IDiscussionBoardModerationAuditLog.IRequest;
  export type Response = IPageIDiscussionBoardModerationAuditLog;

  export const METADATA = {
    method: "PATCH",
    path: "/discussionBoard/administrator/audit/moderation",
    request: {
      type: "application/json",
      encrypted: false,
    },
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = () => "/discussionBoard/administrator/audit/moderation";
  export const random = (): IPageIDiscussionBoardModerationAuditLog =>
    typia.random<IPageIDiscussionBoardModerationAuditLog>();
  export const simulate = (
    connection: IConnection,
    props: index.Props,
  ): Response => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: index.path(),
      contentType: "application/json",
    });
    try {
      assert.body(() => typia.assert(props.body));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}
