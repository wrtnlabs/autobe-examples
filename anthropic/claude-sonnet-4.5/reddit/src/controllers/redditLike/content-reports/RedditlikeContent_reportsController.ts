import { Controller } from "@nestjs/common";
import { TypedRoute, TypedBody, TypedParam } from "@nestia/core";
import typia, { tags } from "typia";
import { postRedditLikeContentReports } from "../../../providers/postRedditLikeContentReports";
import { getRedditLikeContentReportsReportId } from "../../../providers/getRedditLikeContentReportsReportId";
import { ModeratorAuth } from "../../../decorators/ModeratorAuth";
import { ModeratorPayload } from "../../../decorators/payload/ModeratorPayload";

import { IRedditLikeContentReport } from "../../../api/structures/IRedditLikeContentReport";

@Controller("/redditLike/content-reports")
export class RedditlikeContent_reportsController {
  /**
   * Submit a new content report for moderation review.
   *
   * Creates a new content report enabling users to flag posts or comments that
   * violate community rules or platform-wide policies. This operation is
   * fundamental to the platform's distributed moderation system, allowing all
   * users (authenticated members and anonymous guests) to participate in
   * content curation by reporting inappropriate content.
   *
   * The report submission captures comprehensive information including the type
   * of content being reported (post or comment), specific violation categories
   * selected by the reporter (spam, harassment, hate speech, violence, etc.),
   * optional additional context explaining the concern, and metadata for
   * anti-abuse tracking. The system validates that exactly one content type is
   * specified and that the reported content exists and is accessible.
   *
   * Reports are routed to the appropriate moderation queue based on the
   * community context. Community moderators review reports for their assigned
   * communities, while platform administrators handle escalated or
   * platform-wide policy violations. The reporter's identity is kept
   * confidential from the content creator to encourage honest reporting without
   * fear of retaliation.
   *
   * For authenticated members, the report is associated with their user account
   * for tracking report history and preventing abuse. For guest users, reports
   * are marked as anonymous with IP address tracking for security purposes. The
   * system prevents duplicate reports from the same user on the same content
   * within 24 hours to avoid report spam.
   *
   * Upon successful submission, the report enters the moderation queue with
   * pending status. If multiple users report the same content within 24 hours
   * (5+ reports), the system automatically flags it as high priority for
   * expedited moderator review. The operation provides immediate confirmation
   * to the reporter while maintaining confidentiality throughout the moderation
   * workflow.
   *
   * @param connection
   * @param body Content report submission data including reported content
   *   reference, violation categories, and optional context
   * @nestia Generated by Nestia - https://github.com/samchon/nestia
   */
  @TypedRoute.Post()
  public async create(
    @TypedBody()
    body: IRedditLikeContentReport.ICreate,
  ): Promise<IRedditLikeContentReport> {
    try {
      return await postRedditLikeContentReports({
        body,
      });
    } catch (error) {
      console.log(error);
      throw error;
    }
  }

  /**
   * Retrieve detailed information about a specific content report.
   *
   * Retrieve comprehensive details for a specific content report identified by
   * its unique report ID. This operation provides moderators and administrators
   * with all information necessary to review and act on user-submitted reports
   * of potentially inappropriate content.
   *
   * The operation returns complete report information including the type of
   * content being reported (post or comment), the violation categories selected
   * by the reporter, any additional context provided, the current review
   * status, and metadata about when the report was submitted. For authenticated
   * reporters, the system includes the reporter's username to help moderators
   * assess report credibility. For anonymous guest reports, the reporter is
   * identified as 'Anonymous'.
   *
   * This endpoint integrates with the content moderation workflow defined in
   * the Content Moderation and Reporting requirements document. The retrieved
   * report information enables moderators to make informed decisions about
   * whether to remove content, dismiss reports as false positives, ban users,
   * or escalate to administrators. The response includes references to the
   * reported content (post ID or comment ID) allowing moderators to view the
   * content in context before taking action.
   *
   * Security considerations include restricting access to moderators and
   * administrators only, as content reports contain sensitive information about
   * reporters and reported users. The system enforces role-based access control
   * ensuring moderators can only access reports for communities they moderate,
   * while administrators have platform-wide report access.
   *
   * This operation supports the moderator review queue functionality by
   * providing the detailed view when moderators click on queue items to
   * investigate reports thoroughly. The comprehensive report details enable
   * fair and informed moderation decisions that balance community safety with
   * user rights.
   *
   * @param connection
   * @param reportId Unique identifier of the content report to retrieve
   * @nestia Generated by Nestia - https://github.com/samchon/nestia
   */
  @TypedRoute.Get(":reportId")
  public async at(
    @ModeratorAuth()
    moderator: ModeratorPayload,
    @TypedParam("reportId")
    reportId: string & tags.Format<"uuid">,
  ): Promise<IRedditLikeContentReport> {
    try {
      return await getRedditLikeContentReportsReportId({
        moderator,
        reportId,
      });
    } catch (error) {
      console.log(error);
      throw error;
    }
  }
}
