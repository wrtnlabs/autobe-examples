import { IConnection, HttpError } from "@nestia/fetcher";
import { PlainFetcher } from "@nestia/fetcher/lib/PlainFetcher";
import typia, { tags } from "typia";
import { NestiaSimulator } from "@nestia/fetcher/lib/NestiaSimulator";

import { IRedditLikeContentReport } from "../../../structures/IRedditLikeContentReport";

/**
 * Submit a new content report for moderation review.
 *
 * Creates a new content report enabling users to flag posts or comments that
 * violate community rules or platform-wide policies. This operation is
 * fundamental to the platform's distributed moderation system, allowing all
 * users (authenticated members and anonymous guests) to participate in content
 * curation by reporting inappropriate content.
 *
 * The report submission captures comprehensive information including the type
 * of content being reported (post or comment), specific violation categories
 * selected by the reporter (spam, harassment, hate speech, violence, etc.),
 * optional additional context explaining the concern, and metadata for
 * anti-abuse tracking. The system validates that exactly one content type is
 * specified and that the reported content exists and is accessible.
 *
 * Reports are routed to the appropriate moderation queue based on the community
 * context. Community moderators review reports for their assigned communities,
 * while platform administrators handle escalated or platform-wide policy
 * violations. The reporter's identity is kept confidential from the content
 * creator to encourage honest reporting without fear of retaliation.
 *
 * For authenticated members, the report is associated with their user account
 * for tracking report history and preventing abuse. For guest users, reports
 * are marked as anonymous with IP address tracking for security purposes. The
 * system prevents duplicate reports from the same user on the same content
 * within 24 hours to avoid report spam.
 *
 * Upon successful submission, the report enters the moderation queue with
 * pending status. If multiple users report the same content within 24 hours (5+
 * reports), the system automatically flags it as high priority for expedited
 * moderator review. The operation provides immediate confirmation to the
 * reporter while maintaining confidentiality throughout the moderation
 * workflow.
 *
 * @param props.connection
 * @param props.body Content report submission data including reported content
 *   reference, violation categories, and optional context
 * @path /redditLike/content-reports
 * @accessor api.functional.redditLike.content_reports.create
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function create(
  connection: IConnection,
  props: create.Props,
): Promise<create.Response> {
  return true === connection.simulate
    ? create.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...create.METADATA,
          path: create.path(),
          status: null,
        },
        props.body,
      );
}
export namespace create {
  export type Props = {
    /**
     * Content report submission data including reported content reference,
     * violation categories, and optional context
     */
    body: IRedditLikeContentReport.ICreate;
  };
  export type Body = IRedditLikeContentReport.ICreate;
  export type Response = IRedditLikeContentReport;

  export const METADATA = {
    method: "POST",
    path: "/redditLike/content-reports",
    request: {
      type: "application/json",
      encrypted: false,
    },
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = () => "/redditLike/content-reports";
  export const random = (): IRedditLikeContentReport =>
    typia.random<IRedditLikeContentReport>();
  export const simulate = (
    connection: IConnection,
    props: create.Props,
  ): Response => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: create.path(),
      contentType: "application/json",
    });
    try {
      assert.body(() => typia.assert(props.body));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}

/**
 * Retrieve detailed information about a specific content report.
 *
 * Retrieve comprehensive details for a specific content report identified by
 * its unique report ID. This operation provides moderators and administrators
 * with all information necessary to review and act on user-submitted reports of
 * potentially inappropriate content.
 *
 * The operation returns complete report information including the type of
 * content being reported (post or comment), the violation categories selected
 * by the reporter, any additional context provided, the current review status,
 * and metadata about when the report was submitted. For authenticated
 * reporters, the system includes the reporter's username to help moderators
 * assess report credibility. For anonymous guest reports, the reporter is
 * identified as 'Anonymous'.
 *
 * This endpoint integrates with the content moderation workflow defined in the
 * Content Moderation and Reporting requirements document. The retrieved report
 * information enables moderators to make informed decisions about whether to
 * remove content, dismiss reports as false positives, ban users, or escalate to
 * administrators. The response includes references to the reported content
 * (post ID or comment ID) allowing moderators to view the content in context
 * before taking action.
 *
 * Security considerations include restricting access to moderators and
 * administrators only, as content reports contain sensitive information about
 * reporters and reported users. The system enforces role-based access control
 * ensuring moderators can only access reports for communities they moderate,
 * while administrators have platform-wide report access.
 *
 * This operation supports the moderator review queue functionality by providing
 * the detailed view when moderators click on queue items to investigate reports
 * thoroughly. The comprehensive report details enable fair and informed
 * moderation decisions that balance community safety with user rights.
 *
 * @param props.connection
 * @param props.reportId Unique identifier of the content report to retrieve
 * @path /redditLike/content-reports/:reportId
 * @accessor api.functional.redditLike.content_reports.at
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function at(
  connection: IConnection,
  props: at.Props,
): Promise<at.Response> {
  return true === connection.simulate
    ? at.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...at.METADATA,
          path: at.path(props),
          status: null,
        },
      );
}
export namespace at {
  export type Props = {
    /** Unique identifier of the content report to retrieve */
    reportId: string & tags.Format<"uuid">;
  };
  export type Response = IRedditLikeContentReport;

  export const METADATA = {
    method: "GET",
    path: "/redditLike/content-reports/:reportId",
    request: null,
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = (props: Props) =>
    `/redditLike/content-reports/${encodeURIComponent(props.reportId ?? "null")}`;
  export const random = (): IRedditLikeContentReport =>
    typia.random<IRedditLikeContentReport>();
  export const simulate = (
    connection: IConnection,
    props: at.Props,
  ): Response => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: at.path(props),
      contentType: "application/json",
    });
    try {
      assert.param("reportId")(() => typia.assert(props.reportId));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}
