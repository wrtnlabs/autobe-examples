import { IConnection, HttpError } from "@nestia/fetcher";
import { PlainFetcher } from "@nestia/fetcher/lib/PlainFetcher";
import typia from "typia";
import { NestiaSimulator } from "@nestia/fetcher/lib/NestiaSimulator";

import { IRedditLikeModerationAction } from "../../../../structures/IRedditLikeModerationAction";

/**
 * Create a new moderation action to address reported or problematic content.
 *
 * Create a comprehensive moderation action record documenting a moderator or
 * administrator's decision regarding reported content or proactive content
 * management. This operation is the central mechanism for enforcing community
 * rules and platform policies through formal moderation actions.
 *
 * The operation requires specification of the action type (remove, approve,
 * dismiss_report, escalate, restore, lock), the content being acted upon (post
 * or comment), and detailed reasoning for the action. For removal actions, the
 * system requires additional specification of removal scope (community-level,
 * platform-level, or spam removal). The operation associates actions with
 * triggering reports when applicable, creating a complete audit trail linking
 * user reports to moderator responses.
 *
 * When a moderation action is successfully created, the system immediately
 * executes the specified action on the target content. For removal actions,
 * content is hidden from public view within 1 second per performance
 * requirements. For ban-related actions, user permissions are updated
 * immediately. The system automatically sends notifications to affected content
 * authors informing them of the action taken, the reason, and information about
 * the appeal process per requirements section R-REM-015 through R-REM-017.
 *
 * The operation enforces strict authorization rules based on user role and
 * community scope. Moderators can only create moderation actions for
 * communities where they have moderator permissions, while administrators can
 * take actions across all communities. The system validates that the actor
 * (moderator or admin) has appropriate permissions before executing the
 * action.
 *
 * This endpoint integrates deeply with the Content Moderation and Reporting
 * requirements, implementing the core moderation workflow where reports are
 * reviewed and actions are taken. The created moderation action becomes part of
 * the permanent moderation log per requirements section 9, providing
 * accountability and enabling appeals. The action record includes the actor's
 * identity (moderator or admin), timestamps for audit purposes, and detailed
 * reasoning for transparency.
 *
 * For content removal actions specifically, the system follows the removal
 * process defined in requirements section 6, preserving removed content in the
 * database for audit and appeal purposes while hiding it from public view. The
 * removal type field distinguishes between community-level removals (content
 * hidden from community but visible in user profile) and platform-level
 * removals (content completely hidden from all views).
 *
 * Related operations that may be used together include retrieving content
 * reports to review before taking action, and subsequently checking moderation
 * logs to verify action completion.
 *
 * @param props.connection
 * @param props.body Moderation action details including action type, affected
 *   content, removal scope, and detailed reasoning
 * @path /redditLike/moderation/actions
 * @accessor api.functional.redditLike.moderation.actions.create
 * @autobe Generated by AutoBE - https://github.com/wrtnlabs/autobe
 */
export async function create(
  connection: IConnection,
  props: create.Props,
): Promise<create.Response> {
  return true === connection.simulate
    ? create.simulate(connection, props)
    : await PlainFetcher.fetch(
        {
          ...connection,
          headers: {
            ...connection.headers,
            "Content-Type": "application/json",
          },
        },
        {
          ...create.METADATA,
          path: create.path(),
          status: null,
        },
        props.body,
      );
}
export namespace create {
  export type Props = {
    /**
     * Moderation action details including action type, affected content,
     * removal scope, and detailed reasoning
     */
    body: IRedditLikeModerationAction.ICreate;
  };
  export type Body = IRedditLikeModerationAction.ICreate;
  export type Response = IRedditLikeModerationAction;

  export const METADATA = {
    method: "POST",
    path: "/redditLike/moderation/actions",
    request: {
      type: "application/json",
      encrypted: false,
    },
    response: {
      type: "application/json",
      encrypted: false,
    },
  } as const;

  export const path = () => "/redditLike/moderation/actions";
  export const random = (): IRedditLikeModerationAction =>
    typia.random<IRedditLikeModerationAction>();
  export const simulate = (
    connection: IConnection,
    props: create.Props,
  ): Response => {
    const assert = NestiaSimulator.assert({
      method: METADATA.method,
      host: connection.host,
      path: create.path(),
      contentType: "application/json",
    });
    try {
      assert.body(() => typia.assert(props.body));
    } catch (exp) {
      if (!typia.is<HttpError>(exp)) throw exp;
      return {
        success: false,
        status: exp.status,
        headers: exp.headers,
        data: exp.toJSON().message,
      } as any;
    }
    return random();
  };
}
